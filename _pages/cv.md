---
layout: archive
title: "CV"
permalink: /cv/
author_profile: true
redirect_from:
  - /resume
---

{% include base_path %}

## Education
**B.S., University of Electronic Science and Technology of China (UESTC), Expected 2025**
- **GPA:** 3.99/4.00, **Average Score:** 92.41/100,  **Ranking:** 2/150,  **CET4:** 529 **CET6:** 464
- **Hobbies:** Running, Football, Badminton
- **Roles:** Member of School Technology Studio YOLO

## Academic Experience 
**Research Assistant in State Key Laboratory of Internet of Things for Smart City, University of Macau**
**Supervisor:** Assistant Professor Li Li
**Research Focus:** Large Language Models Compression, Lightweight Deployment of Large Language Models, Federated Learning
- **Research 1:** We proposed GreenLLM, a framework for efficient pruning of Large Language Models (LLMs) designed for lightweight large-scale deployment. This framework integrates a physical hardware-based energy estimation scheme and a pruning rate generator that takes into account Space, Weight, and Power (SWaP), enabling effective deployment on resource-constrained edge devices. Experimental results indicate that GreenLLM reduces energy consumption by 34.1% and latency by 33.5%, with only a minimal impact on performance. This work has been accepted as a co-first authored paper at the CCF-B ranked international conference, **IWQoS**.
- **Research 2:** We conducted research on Federated Learning (FL) and developed FedRank, a novel framework designed to optimize device selection for collaborative model training in FL environments. FedRank has demonstrated the ability to enhance model accuracy by 5.2% to 56.9% on datasets like MNIST and CIFAR-10, increase training convergence speed by 2.01 times, and reduce energy consumption by up to 40.1%. This work has been accepted as a third-author paper at the CCF-A ranked top international conference, **ICML**.
- **Research 3:** We presented AutoPruner, a novel adaptive pruning framework that approaches the pruning of large language models (LLMs) as a generative task. This framework leverages a data-driven encoder-evaluator-decoder architecture to dynamically determine the optimal pruning configuration through gradient optimization, significantly reducing the need for manual pruning efforts. Our experiments demonstrate that AutoPruner surpasses recent model compression techniques such as LLM Runner, SliceGPT, and ShortGPT on datasets including Wikitext2, PTB, BoolQ, and PIQA, achieving an overall pruning rate of 20% while preserving 95% of the base model's performance. These research findings have been submitted as a co-first author paper to the CCF-B ranked international conference, **ECAI**.
- **Research 4:** We are developing a method called EdgeLLM for power-friendly pruning and lightweight deployment of Large Language Models (LLMs). EdgeLLM begins by using an Offline Heuristic Pruning Rate Generator to establish a pruning configuration that balances performance needs with minimal power consumption. This configuration is then deployed to edge devices. An Online algorithm dynamically adjusts the voltage and frequency of these devices to further decrease power consumption and latency. We plan to submit our findings as co-first authors to the CCF-A ranked top international conference, **EuroSys**.

## Projects
**Design and Development of Image Processing Software**
- We developed an image processing software on the Android platform, integrating and optimizing existing algorithms such as the MeanShift, Mean Blur, and bilinear interpolation to fulfill the software's basic functional requirements. Additionally, we employed MDC Android to enhance the software's UI aesthetics.
- I was responsible for implementing and optimizing key image processing algorithms, including enhancing image grayscale processing through histogram equalization to improve image depth and contrast while preventing overall darkness or bias. Additionally, I refined the Mean Blur algorithm using the Gaussian Blur technique to more effectively eliminate image noise (excluding salt and pepper noise). I also handled the integration and testing of various project components.

**Design and Implementation of a ZigBee-Based Wireless Communication System**
- We developed a ZigBee-based wireless communication system using the STM32F103 development board. The system enables a data receiving terminal to communicate with multiple data acquisition terminals via ZigBee wireless technology, receiving data transmitted back from these terminals. Additionally, it allows for the transmission of configuration data to various data collection terminals for parameter adjustments.
- I was responsible for designing the architecture for data collection and reception terminals; implementing data receiver code using Keil5 software and C language; designing finite state machines for data processing; and configuring ZigBee devices, including baud rate, channel, and mode.

## Awards
- Chinese Colleges Computer Competition - Network Technology Challenge: 
- University of Electronic Science and Technology: **Excellent Student Scholarship** *2
- Blue Bridge Cup Software Design Python Group: **Provincial Second Prize**
- National Computer Design Competition: **Provincial Third Prize**
- National E-commerce "Innovation and Entrepreneurship" Competition: **Provincial Third Prize**
- University of Electronic Science and Technology "Ginkgo Fruit Fund": **One project successfully completed**
- School of Information and Software Engineering, University of Electronic Science and Technology: **Award for Outstanding Studio**

## Skills
- **Language:** Python (Pytorch for Neural Networks, Flask for Web), C/C++, Java, Golang, SQL
- **Platform:** Linux, Windows, Mac, Tencent Cloud
- **Techniques:** Deep Learning, Data Analysis, Academic Drawing, Product Design, Algorithm Design, System Architecture Design, Software Testing
- **Abilities:** Public Speaking and Presentation, Team Coordination and Organization, Ability to solve complex engineering problems, Quick learner of new knowledge, Proficient in productivity tools such as Office, Obsidian, and Notion.

-----
